{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note\n",
    "Some k-cross validation used when trying out kaggle bnank churn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.metrics import Accuracy\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, MinMaxScaler\n",
    "\n",
    "input_shape = loaded_data.shape[1:]\n",
    "input_shape\n",
    "\n",
    "\n",
    "\n",
    "def build_model():\n",
    "  inputs = layers.Input(shape=input_shape)\n",
    "  hidden = layers.Dense(40, activation='relu')(inputs)\n",
    "  hidden = layers.Dropout(0.2)(hidden)\n",
    "  hidden = layers.Dense(10, activation='relu')(hidden)\n",
    "  hidden = layers.Dropout(0.2)(hidden) \n",
    "  outputs = layers.Dense(1)(hidden)\n",
    "\n",
    "  model = keras.models.Model(inputs=inputs, outputs=outputs) \n",
    "\n",
    "  model.compile(optimizer=RMSprop(),\n",
    "                loss=BinaryCrossentropy(),\n",
    "                metrics=[keras.metrics.BinaryAccuracy()])\n",
    "  \n",
    "  return model\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=3,\n",
    "        verbose=0,\n",
    "    ),\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        '/kaggle/working/models/best_model.keras', \n",
    "        monitor='accuracy',\n",
    "        save_best_only=True\n",
    "    )\n",
    "]\n",
    "\n",
    "cv = KFold(n_splits=6, shuffle=True, random_state=42)\n",
    "data = loaded_data.to_numpy()\n",
    "labels = loaded_labels.to_numpy()\n",
    "\n",
    "fold_num = 1\n",
    "all_accuracy_histories = []\n",
    "all_loss_histories = []\n",
    "\n",
    "for train_i, val_i in cv.split(data, labels):\n",
    "  print(f\"Processing fold #{fold_num}\")\n",
    "  scaler = StandardScaler()\n",
    "  train_data = data[train_i]\n",
    "  val_data = data[val_i]\n",
    "  scaler.fit(train_data)\n",
    "  train_data = scaler.transform(train_data)\n",
    "  val_data = scaler.transform(val_data)\n",
    "\n",
    "  model = build_model()\n",
    "\n",
    "  if (fold_num == 1):\n",
    "    model.summary()\n",
    "\n",
    "  history = model.fit(train_data,\n",
    "                      labels[train_i],\n",
    "                      epochs=10,\n",
    "                      batch_size = 128,\n",
    "                      validation_data=(val_data, labels[val_i]),\n",
    "                      callbacks=callbacks)\n",
    "\n",
    "\n",
    "  # accuracy_history = history.history[\"val_accuracy\"]\n",
    "  # loss_history = history.history[\"val_loss\"]\n",
    "  # all_accuracy_histories.append(accuracy_history)\n",
    "  # all_loss_histories.append(loss_history)\n",
    "  fold_num += 1\n",
    "\n",
    "# average_accuracy_history = [\n",
    "#     np.mean([x[i] for x in all_accuracy_histories]) for i in range(10)]\n",
    "\n",
    "# plt.plot(range(1, len(average_accuracy_history) + 1), average_accuracy_history)\n",
    "# plt.xlabel(\"Epochs\")\n",
    "# plt.ylabel(\"Validation Accuracy\")\n",
    "# plt.show()\n",
    "\n",
    "# average_loss_history = [\n",
    "#     np.mean([x[i] for x in all_loss_histories]) for i in range(10)]\n",
    "\n",
    "# plt.plot(range(1, len(average_loss_history) + 1), average_loss_history)\n",
    "# plt.xlabel(\"Epochs\")\n",
    "# plt.ylabel(\"Validation Loss\")\n",
    "# plt.show()\n",
    "\n",
    "  \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
